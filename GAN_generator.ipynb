{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb1d8f4-b412-48a7-ae91-b6383e5fab9a",
   "metadata": {},
   "source": [
    "# GAN Generator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50c6ad-6ec5-401d-81dc-bb890a1b49ea",
   "metadata": {},
   "source": [
    "Default Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc44167-6ffc-4a82-9997-358feae5f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de1f0e-ab4f-4efe-86f8-b126f2af6677",
   "metadata": {},
   "source": [
    "## Loading pre-trained Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3090ea8f-846d-4928-8856-95100f7b1a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurrogateVAE(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (film_layer): FiLMLayer(\n",
       "    (scale_transform): Linear(in_features=77, out_features=256, bias=True)\n",
       "    (shift_transform): Linear(in_features=77, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=262221, out_features=1024, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=262144, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Unflatten(dim=1, unflattened_size=(256, 32, 32))\n",
       "    (5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.neural_rendering import RenderDataset, Evaluator, SurrogateVAE, Inference\n",
    "\n",
    "def full_path(relative_path):\n",
    "    return os.path.join(base_path, relative_path)\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    base_path = '/content/drive/MyDrive/Master-Thesis'\n",
    "else:\n",
    "    base_path = ''\n",
    "\n",
    "num_params = 77\n",
    "\n",
    "rig_params_json_path = full_path('data/render_trainset/rendering_rig_params.json')\n",
    "train_set_path = full_path('data/render_trainset')\n",
    "idle_img_path = full_path('data/render_trainset/idle.png')\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SurrogateVAE(num_params=num_params)\n",
    "model.load_state_dict(torch.load('checkpoints/Neural_Rendering/model_weights_77.pth', map_location=torch.device('cpu')))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa20eba-7662-4bb9-9115-a8b31ad14e14",
   "metadata": {},
   "source": [
    "### Test inference with Surrogate Variational Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75fd510-6133-4626-8e7b-783498404422",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rig_param_values = [0, 0, -2, 0.0, 0.0, 0.0, 0.0, 0, 0.2, -0.3, 0.0, 0.0, 0.0, 0.0, -0.1, -0.01, -0.1, 0.0, 0.0, 0.0, 0.0, -0.1, 0.1, -4, 0.0, 0.0, 0.0, 0.0, 0.1, -0.03, -0.2, 0.0, 0.0, 0.0, 0.0, 0.02, 0.01, 0.16, 0.0, 0.0, 0.0, 0.0, -0.35, 0.14, -0.30, 0.0, 3.002625589942909e-06, -5.607937964668963e-06, 8.361090294783935e-06, -0.06107807159423828, 0.15036296844482422, -0.119140625, 0.0, 4.3709578676498495e-06, 7.03985597283463e-06, -8.000141860975418e-06, -0.22553014755249023, 0.1323099136352539, -0.433349609375, 0.0, -1.8065652511722874e-06, -5.944726581219584e-06, 0.0, -0.5, 0.5, 0.1, 0.0, 0.0, 0.0, 0.0, 0.01, -0.5, 0.16, 0.0, 0.0, 0.0, 0.0]\n",
    "rig_params = torch.tensor([rig_param_values], dtype=torch.float32).to(device)\n",
    "\n",
    "vae_evaluator = Inference(model, idle_img_path, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "vae_output = vae_evaluator.inference(rig_params)\n",
    "vae_evaluator.inference_display_results(vae_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be861af-52cf-41f0-81d5-a45c9642ce36",
   "metadata": {},
   "source": [
    "## Setup pre-trained DeepFace Emotion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f3f2f-4af4-4499-86c7-2e118595cbab",
   "metadata": {},
   "source": [
    "Outputs the Emotion scores for the sample rendering we just created with the pre-trained VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c100733-377a-4fe1-be03-a57202018ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 81.68504456459945, 'disgust': 0.00185413715096232, 'fear': 0.05763246340029378, 'happy': 2.015825120708332, 'sad': 3.0020030362006382, 'surprise': 2.767953877990976, 'neutral': 10.469681266584246}\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "emotion_score = DeepFace.analyze(vae_output, actions = ['emotion'], enforce_detection = False)[0]['emotion']\n",
    "print(emotion_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe11d1-5f92-45e8-8f55-c773034192fd",
   "metadata": {},
   "source": [
    "## GAN Setup and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70556e8e-dc92-439b-b628-9eb935a2c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.generator import Generator, GANTrainer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa7a1d73-d8cf-492b-8eea-b21d45be9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    base_path = '/content/drive/MyDrive/Master-Thesis'\n",
    "else:\n",
    "    base_path = ''\n",
    "\n",
    "generator = Generator(num_emotions=7, hidden_dim=128, output_dim=77, num_params=77, base_path=base_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28f01545-660b-49bf-88c6-2afbbf1745be",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GANTrainer(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfac8e43-f6e9-4013-bbba-ca7d66b6355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader with random one-hot encoded emotion vectors\n",
    "num_samples = 100\n",
    "emotions = torch.randint(0, 7, (num_samples,))  # Random integers for 7 emotion states\n",
    "one_hot_emotions = F.one_hot(emotions, num_classes=7).float().to(device)\n",
    "rig_params = torch.randn(num_samples, generator.num_params).to(device)  # Random rig parameters as dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3170f021-e543-4005-999d-071dece31283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader setup\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dataset = TensorDataset(one_hot_emotions, rig_params)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b80c6b-412a-407f-9cfb-4c561014a713",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "trainer.train(dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce337c56-f54f-482d-84f7-83eb266cd975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
